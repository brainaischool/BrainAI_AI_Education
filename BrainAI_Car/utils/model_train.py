"""
BrainAI Car ììœ¨ì£¼í–‰ ë„ë¡œ ì¸ì‹ ëª¨ë¸ í›ˆë ¨ (MobileNet ë²„ì „)_v1.0.0
utils/model_model.py

ì´ ëª¨ë“ˆì€:
1. dataset_laneD1 í´ë”ì˜ train/validation ë°ì´í„°ë¥¼ ì½ì–´ì„œ
2. MobileNet ê¸°ë°˜ Transfer Learningìœ¼ë¡œ CNN ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚µë‹ˆë‹¤

[ì£¼ìš” íŠ¹ì§•]
- MobileNet Transfer Learning ì‚¬ìš©
- ë¹ ë¥¸ í•™ìŠµ ì†ë„
- ì ì€ ë°ì´í„°ë¡œë„ ë†’ì€ ì„±ëŠ¥
- êµìœ¡ìš© ìƒì„¸ ì£¼ì„

[í•™ìŠµ ëª©í‘œ]
- Transfer Learningì´ ë¬´ì—‡ì¸ì§€ ì´í•´í•˜ê¸°
- MobileNet êµ¬ì¡° ì´í•´í•˜ê¸°
- ì‹¤ë¬´ì—ì„œ ì‚¬ìš©í•˜ëŠ” íš¨ìœ¨ì ì¸ AI ê°œë°œ ë°©ë²• ë°°ìš°ê¸°
"""

import os
import json
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import cv2
import matplotlib.pyplot as plt
from datetime import datetime
import platform


# ============================================================================
# ğŸ“ 1ë‹¨ê³„: ì„¤ì • í´ë˜ìŠ¤ (Configuration)
# ============================================================================

class TrainingConfig:
    """
    í›ˆë ¨ ì„¤ì •ì„ ë‹´ëŠ” í´ë˜ìŠ¤
    
    [ì¤‘ìš” ê°œë…]
    - ì„¤ì •ì„ í•œ ê³³ì— ëª¨ì•„ë‘ë©´ ë‚˜ì¤‘ì— ìˆ˜ì •í•˜ê¸° ì‰¬ì›Œìš”!
    - ê° ê°’ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤
    
    [ìƒˆë¡œìš´ ê¸°ëŠ¥ - Aì—ì„œ ê°€ì ¸ì˜´]
    - use_augmentation: ë°ì´í„° ì¦ê°• ì‚¬ìš© ì—¬ë¶€
    - augmentation_options: ì¦ê°• ì˜µì…˜ ì„ íƒ
    """
    
    def __init__(
        self,
        dataset_laneD1_path="dataset_laneD1",      # ë°ì´í„°ì…‹ ê²½ë¡œ
        model_name="brainai_car",    # ëª¨ë¸ ì´ë¦„
        epochs=50,                   # í›ˆë ¨ ë°˜ë³µ íšŸìˆ˜
        batch_size=32,               # í•œë²ˆì— ì²˜ë¦¬í•  ì´ë¯¸ì§€ ìˆ˜
        img_height=224,              # ì´ë¯¸ì§€ ë†’ì´
        img_width=224,               # ì´ë¯¸ì§€ ë„ˆë¹„
        learning_rate=0.001,         # í•™ìŠµ ì†ë„
        use_augmentation=False,      # ë°ì´í„° ì¦ê°• ì‚¬ìš©
        augmentation_options=None    # ì¦ê°• ì˜µì…˜
    ):
        
        self.dataset_laneD1_path = dataset_laneD1_path
        self.model_name = model_name
        self.epochs = epochs
        self.batch_size = batch_size
        self.img_height = img_height
        self.img_width = img_width
        self.learning_rate = learning_rate
        self.use_augmentation = use_augmentation
        self.augmentation_options = augmentation_options or {
            'COLOR_JITTER': False,      # âœ… ìƒ‰ìƒ/ë°ê¸° ë³€í™” (ì•ˆì „)
            'GAUSSIAN_NOISE': False     # âœ… ë…¸ì´ì¦ˆ ì¶”ê°€ (ì•ˆì „)
        }
        
    def print_summary(self):
        """ì„¤ì • ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ í›ˆë ¨ ì„¤ì •")
        print("=" * 60)
        print(f"ğŸ“‚ ë°ì´í„°ì…‹: {self.dataset_laneD1_path}")
        print(f"ğŸ·ï¸  ëª¨ë¸ëª…: {self.model_name}")
        print(f"ğŸ” ì—í¬í¬(ë°˜ë³µ): {self.epochs}íšŒ")
        print(f"ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {self.batch_size}ê°œ")
        print(f"ğŸ–¼ï¸  ì´ë¯¸ì§€ í¬ê¸°: {self.img_width}x{self.img_height}")
        print(f"âš¡ í•™ìŠµë¥ : {self.learning_rate}")
        print(f"ğŸ¨ ë°ì´í„° ì¦ê°•: {'ì‚¬ìš©' if self.use_augmentation else 'ë¯¸ì‚¬ìš©'}")
        
        if self.use_augmentation:
            print("\n  ğŸ“Š ì¦ê°• ì˜µì…˜ (ììœ¨ì£¼í–‰ ì•ˆì „ ì¦ê°•ë§Œ):")
            
            # ì•ˆì „í•œ ì˜µì…˜
            safe_options = []
            if self.augmentation_options.get('COLOR_JITTER', False):
                safe_options.append("Color Jitter (ìƒ‰ìƒ/ë°ê¸° ë³€í™”)")
            if self.augmentation_options.get('GAUSSIAN_NOISE', False):
                safe_options.append("Gaussian Noise (ë…¸ì´ì¦ˆ ì¶”ê°€)")
            
            if safe_options:
                print("    âœ… ì•ˆì „í•œ ì¦ê°•:")
                for opt in safe_options:
                    print(f"       - {opt}")
            else:
                print("    (ì„ íƒëœ ì•ˆì „í•œ ì¦ê°• ì—†ìŒ)")
        
        print("=" * 60)


# ============================================================================
# ğŸ“ 2ë‹¨ê³„: ë°ì´í„° ì²˜ë¦¬ í´ë˜ìŠ¤ (Data Utilities)
# ============================================================================

class DataLoader:
    """
    ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ì „ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤
    
    [ì¤‘ìš” ê°œë…]
    - ì´ë¯¸ì§€ë¥¼ ì»´í“¨í„°ê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ«ìë¡œ ë³€í™˜í•´ìš”
    - ì •ê·œí™”(Normalization): ê°’ì„ ì¼ì • ë²”ìœ„ë¡œ ì¡°ì •í•˜ì—¬ í•™ìŠµì„ ì‰½ê²Œ ë§Œë“¤ì–´ìš”
    
    [MobileNet ì „ì²˜ë¦¬ íŠ¹ì§•]
    - ì •ê·œí™” ë²”ìœ„: -1 ~ 1 (MobileNet í‘œì¤€)
    - ìƒë‹¨ ë§ˆìŠ¤í‚¹: í•˜ëŠ˜/ë°°ê²½ ë¶€ë¶„ ì œê±°
    """
    
    def __init__(self, config: TrainingConfig):
        self.config = config
        
        # ê²½ë¡œ ì„¤ì •
        self.train_images_path = os.path.join(config.dataset_laneD1_path, "train", "images")
        self.train_annotations_path = os.path.join(config.dataset_laneD1_path, "train", "annotations")
        self.val_images_path = os.path.join(config.dataset_laneD1_path, "validation", "images")
        self.val_annotations_path = os.path.join(config.dataset_laneD1_path, "validation", "annotations")
    
    def apply_augmentation(self, img):
        """
        ë°ì´í„° ì¦ê°• ì ìš©
        
        [ììœ¨ì£¼í–‰ ë°ì´í„° ì¦ê°• ì›ì¹™] âš ï¸ ë§¤ìš° ì¤‘ìš”!
        
        âœ… ì•ˆì „í•œ ì¦ê°• (Pixel-level):
        - ë°ê¸°, ëŒ€ë¹„, ìƒ‰ìƒ ë³€í™”
        - ë…¸ì´ì¦ˆ ì¶”ê°€
        - ë¸”ëŸ¬ íš¨ê³¼
        â†’ ë„ë¡œì˜ "ìœ„ì¹˜"ëŠ” ê·¸ëŒ€ë¡œ, "ë³´ì´ëŠ” ë°©ì‹"ë§Œ ë³€ê²½
        â†’ ì¡°í–¥ê°’ ë³€ê²½ ë¶ˆí•„ìš”
        
        âŒ ìœ„í—˜í•œ ì¦ê°• (Spatial):
        - ì¢Œìš°/ìƒí•˜ ë°˜ì „
        - íšŒì „, ì´ë™
        - ì›ê·¼ ë³€í™˜
        â†’ ë„ë¡œì˜ "ìœ„ì¹˜"ê°€ ë³€ê²½ë¨
        â†’ ì¡°í–¥ê°’ë„ í•¨ê»˜ ë³€ê²½í•´ì•¼ í•˜ëŠ”ë° ì—¬ê¸°ì„œëŠ” ë¶ˆê°€ëŠ¥
        
        [ì˜ˆì‹œë¡œ ì´í•´í•˜ê¸°]
        ìƒí™©: ì™¼ìª½ìœ¼ë¡œ êº¾ëŠ” ë„ë¡œ (ì¡°í–¥ê°’ 30ë„)
        
        âœ… ë°ê¸° ë³€ê²½: ì–´ë‘ìš´ ì™¼ìª½ ë„ë¡œ
        â†’ ì—¬ì „íˆ ì™¼ìª½ì´ë¯€ë¡œ ì¡°í–¥ê°’ 30ë„ ìœ ì§€ (OK!)
        
        âŒ ì¢Œìš° ë°˜ì „: ì˜¤ë¥¸ìª½ìœ¼ë¡œ êº¾ëŠ” ë„ë¡œ
        â†’ ì˜¤ë¥¸ìª½ì¸ë° ì¡°í–¥ê°’ì€ 30ë„(ì™¼ìª½) (ìœ„í—˜!)
        â†’ ì¡°í–¥ê°’ì„ 70ë„(ì˜¤ë¥¸ìª½)ë¡œ ë°”ê¿”ì•¼ í•˜ëŠ”ë°
            ì´ í•¨ìˆ˜ì—ì„œëŠ” ì´ë¯¸ì§€ë§Œ ì²˜ë¦¬í•˜ë¯€ë¡œ ë¶ˆê°€ëŠ¥
        """
        if not self.config.use_augmentation:
            return img
        
        # âœ… Color Jitter (ìƒ‰ìƒ ë³€í™”) - ì•ˆì „í•¨
        if self.config.augmentation_options.get('COLOR_JITTER', False):
            if np.random.random() > 0.5:
                # ë°ê¸° ì¡°ì • (0.8~1.2ë°°)
                brightness_factor = np.random.uniform(0.8, 1.2)
                img = np.clip(img * brightness_factor, 0, 1)
                
                # ëŒ€ë¹„ ì¡°ì • (0.8~1.2ë°°)
                if np.random.random() > 0.5:
                    contrast_factor = np.random.uniform(0.8, 1.2)
                    mean = np.mean(img)
                    img = np.clip((img - mean) * contrast_factor + mean, 0, 1)
        
        # âœ… Gaussian Noise (ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ) - ì•ˆì „í•¨
        if self.config.augmentation_options.get('GAUSSIAN_NOISE', False):
            if np.random.random() > 0.5:
                # ì„¼ì„œ ë…¸ì´ì¦ˆ ì‹œë®¬ë ˆì´ì…˜
                noise = np.random.normal(0, 0.05, img.shape)
                img = np.clip(img + noise, 0, 1)
        
        return img
    
    def load_image_and_label(self, img_path, json_path):
        """
        ì´ë¯¸ì§€ì™€ ë¼ë²¨(ì¡°í–¥ê°’) í•œ ìŒì„ ë¶ˆëŸ¬ì˜¤ê¸°
        
        [MobileNet ì „ì²˜ë¦¬ ê³¼ì •]
        1. ì´ë¯¸ì§€ íŒŒì¼ ì½ê¸°
        2. í¬ê¸° ì¡°ì • (ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ê°™ì€ í¬ê¸°ë¡œ)
        3. ìƒ‰ìƒ ë³€í™˜ (BGR â†’ RGB)
        4. ì •ê·œí™” (0~255 â†’ 0~1)
        5. ë°ì´í„° ì¦ê°• ì ìš© (ì„ íƒì‚¬í•­)
        6. ìƒë‹¨ ë§ˆìŠ¤í‚¹ (í•˜ëŠ˜ ë¶€ë¶„ ì œê±°)
        7. MobileNet ì •ê·œí™” (0~1 â†’ -1~1)
        8. JSONì—ì„œ ì¡°í–¥ê°’ ì½ê¸° (-1~1 ë²”ìœ„)
        """
        # 1. ì´ë¯¸ì§€ ì½ê¸°
        img = cv2.imread(img_path)
        if img is None:
            print(f"  âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {os.path.basename(img_path)}")
            return None, None
        
        # 2. í¬ê¸° ì¡°ì •
        img = cv2.resize(img, (self.config.img_width, self.config.img_height))
        
        # 3. BGR â†’ RGB ë³€í™˜
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # 4. ì •ê·œí™”: 0~255 â†’ 0~1
        img = img.astype(np.float32) / 255.0
        
        # 5. ë°ì´í„° ì¦ê°• ì ìš©
        img = self.apply_augmentation(img)
               
        # 6. MobileNet ì „ì²˜ë¦¬: 0~1 â†’ -1~1
        img = img * 2.0 - 1.0
        
        # 7. JSON ì½ê¸° ë° ê²€ì¦
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
                # 'steering' í‚¤ í™•ì¸
                if 'steering' not in data:
                    print(f"  âš ï¸ 'steering' í‚¤ê°€ ì—†ìŒ: {os.path.basename(json_path)}")
                    return None, None
                
                steering = data['steering']
                
                # ì¡°í–¥ê°’ íƒ€ì… ê²€ì¦
                if not isinstance(steering, (int, float)):
                    print(f"  âš ï¸ ì˜ëª»ëœ ì¡°í–¥ê°’ íƒ€ì…: {os.path.basename(json_path)}")
                    return None, None
                
                # ì¡°í–¥ê°’ ë²”ìœ„ ê²€ì¦ ë° í´ë¦¬í•‘
                if not (-1.0 <= steering <= 1.0):
                    print(f"  âš ï¸ ì¡°í–¥ê°’ ë²”ìœ„ ì´ˆê³¼ ({steering}): {os.path.basename(json_path)}")
                    steering = max(-1.0, min(1.0, steering))

                return img, steering
                
        except json.JSONDecodeError:
            print(f"  âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {os.path.basename(json_path)}")
            return None, None
        except FileNotFoundError:
            print(f"  âš ï¸ JSON íŒŒì¼ ì—†ìŒ: {os.path.basename(json_path)}")
            return None, None
        except Exception as e:
            print(f"  âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {os.path.basename(json_path)} - {e}")
            return None, None
    
    def load_dataset_laneD1(self, images_dir, annotations_dir):
        """ì „ì²´ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸° (ê²€ì¦ ê°•í™”)"""
        images = []
        labels = []
        failed_files = []
        
        if not os.path.exists(images_dir):
            print(f"âš ï¸ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {images_dir}")
            return np.array([]), np.array([])
        
        # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        image_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.jpg')])
        total_files = len(image_files)
        
        if total_files == 0:
            print(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {images_dir}")
            return np.array([]), np.array([])
        
        print(f"ğŸ“‚ {total_files}ê°œ ì´ë¯¸ì§€ ë°œê²¬...")
        
        loaded_count = 0
        for idx, img_file in enumerate(image_files, 1):
            # ì´ë¯¸ì§€ ê²½ë¡œ
            img_path = os.path.join(images_dir, img_file)
            
            # JSON ê²½ë¡œ
            base_name = os.path.splitext(img_file)[0]
            json_path = os.path.join(annotations_dir, f"{base_name}.json")
            
            # ì´ë¯¸ì§€ì™€ ë¼ë²¨ ë¡œë“œ
            img, label = self.load_image_and_label(img_path, json_path)
            
            if img is not None and label is not None:
                images.append(img)
                labels.append(label)
                loaded_count += 1
            else:
                failed_files.append(img_file)
                            
            # 10%ë§ˆë‹¤ í‘œì‹œ
            if idx % max(1, total_files // 10) == 0:
                progress = (idx / total_files) * 100
                print(f"â³ ì§„í–‰ì¤‘... {progress:.0f}%")
        
        print(f"\n  âœ… {loaded_count}ê°œ ë¡œë“œ ì™„ë£Œ! (100.0%)              ")
        
        # ë¡œë“œ ì„±ê³µë¥  ê³„ì‚°
        success_rate = (loaded_count / total_files * 100) if total_files > 0 else 0
        
        # ì‹¤íŒ¨ íŒŒì¼ ìƒì„¸ ì •ë³´
        if failed_files:
            print(f"\n  âš ï¸ {len(failed_files)}ê°œ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ (ì‹¤íŒ¨ìœ¨: {100-success_rate:.1f}%)")
            if len(failed_files) <= 10:
                print(f"     ì‹¤íŒ¨í•œ íŒŒì¼ ëª©ë¡:")
                for f in failed_files:
                    print(f"       - {f}")
            else:
                print(f"     ì‹¤íŒ¨í•œ íŒŒì¼ ì˜ˆì‹œ (ì²˜ìŒ 10ê°œ):")
                for f in failed_files[:10]:
                    print(f"       - {f}")
                print(f"     ... ì™¸ {len(failed_files)-10}ê°œ")
        
        # ğŸ”´ ì‹¬ê°í•œ ë¬¸ì œ: ë¡œë“œ ì„±ê³µë¥ ì´ ë„ˆë¬´ ë‚®ìŒ
        if success_rate < 50:
            print(f"\n  ğŸ”´ ì‹¬ê°í•œ ì˜¤ë¥˜: ë¡œë“œ ì„±ê³µë¥  {success_rate:.1f}%")
            print(f"     ì „ì²´ {total_files}ê°œ ì¤‘ {loaded_count}ê°œë§Œ ë¡œë“œë¨")
            print(f"\n  ğŸ’¡ ê°€ëŠ¥í•œ ì›ì¸:")
            print(f"     1. JSON íŒŒì¼ì´ ì—†ê±°ë‚˜ ì†ìƒë¨")
            print(f"     2. ì´ë¯¸ì§€ íŒŒì¼ì´ ì†ìƒë¨")
            print(f"     3. 'steering' í‚¤ê°€ ì—†ê±°ë‚˜ ê°’ì´ ì˜ëª»ë¨")
            print(f"     4. íŒŒì¼ëª…ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ (ì˜ˆ: image_001.jpg â†” image_001.json)")
            print(f"\n  âŒ ë°ì´í„°ë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”!")
            raise ValueError(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ìœ¨ì´ ë„ˆë¬´ ë†’ìŠµë‹ˆë‹¤ ({100-success_rate:.1f}%)")
        
        # ğŸŸ¡ ì£¼ì˜: ë¡œë“œ ì„±ê³µë¥ ì´ ë‚®ìŒ
        elif success_rate < 80:
            print(f"\n  âš ï¸ ì£¼ì˜: ë¡œë“œ ì„±ê³µë¥  {success_rate:.1f}%")
            print(f"     ì „ì²´ {total_files}ê°œ ì¤‘ {loaded_count}ê°œ ë¡œë“œë¨")
            print(f"     {len(failed_files)}ê°œ íŒŒì¼ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤")
            print(f"\n  ğŸ’¡ ê¶Œì¥ì‚¬í•­:")
            print(f"     - ì‹¤íŒ¨í•œ íŒŒì¼ë“¤ì„ í™•ì¸í•˜ì—¬ ìˆ˜ì •í•˜ì„¸ìš”")
            print(f"     - 80% ë¯¸ë§Œì˜ ì„±ê³µë¥ ì€ ëª¨ë¸ ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        # âœ… ì •ìƒ: ë¡œë“œ ì„±ê³µë¥ ì´ ë†’ìŒ
        elif success_rate >= 80:
            print(f"\n  âœ… ë¡œë“œ ì„±ê³µë¥ : {success_rate:.1f}%")
            if failed_files:
                print(f"     ({len(failed_files)}ê°œ íŒŒì¼ ì œì™¸ë¨)")
        
        # ğŸ”´ ì ˆëŒ€ ë°ì´í„° ìˆ˜ ê²€ì¦ (ìƒˆë¡œìš´ ê¸°ì¤€)
        print(f"\n  ğŸ“Š ë°ì´í„° í’ˆì§ˆ í‰ê°€:")
        if loaded_count < 100:
            print(f"     ğŸ”´ ë§¤ìš° ë¶€ì¡±: {loaded_count}ê°œ")
            print(f"        â†’ ìµœì†Œ 100ê°œ í•„ìš”, í•™ìŠµ ì‹¤íŒ¨ ê°€ëŠ¥ì„± ë†’ìŒ")
            raise ValueError(f"ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤ ({loaded_count}ê°œ). ìµœì†Œ 100ê°œ í•„ìš”!")
        elif loaded_count < 300:
            print(f"     ğŸŸ¡ ë¶€ì¡±: {loaded_count}ê°œ")
            print(f"        â†’ ê¸°ë³¸ í•™ìŠµ ê°€ëŠ¥í•˜ë‚˜ 500ê°œ ì´ìƒ ê¶Œì¥")
        elif loaded_count < 500:
            print(f"     ğŸŸ¢ ë³´í†µ: {loaded_count}ê°œ")
            print(f"        â†’ ê¸°ë³¸ í•™ìŠµ ê°€ëŠ¥")
        elif loaded_count < 1000:
            print(f"     ğŸŸ¢ ì–‘í˜¸: {loaded_count}ê°œ")
            print(f"        â†’ ì¢‹ì€ í•™ìŠµ ì„±ëŠ¥ ê¸°ëŒ€")
        else:
            print(f"     ğŸŒŸ ìš°ìˆ˜: {loaded_count}ê°œ")
            print(f"        â†’ ë§¤ìš° ì¢‹ì€ í•™ìŠµ ì„±ëŠ¥ ê¸°ëŒ€")
        
        return np.array(images), np.array(labels)

    def load_all_data(self):
        """í›ˆë ¨ ë° ê²€ì¦ ë°ì´í„° ëª¨ë‘ ë¡œë“œ"""
        print("\n" + "=" * 60)
        print("ğŸ“¥ ë°ì´í„° ë¡œë“œ ì¤‘...")
        print("=" * 60)
        
        # í›ˆë ¨ ë°ì´í„°
        print("\n[í›ˆë ¨ ë°ì´í„°]")
        train_images, train_labels = self.load_dataset_laneD1(
            self.train_images_path,
            self.train_annotations_path
        )
        
        # ê²€ì¦ ë°ì´í„°
        print("\n[ê²€ì¦ ë°ì´í„°]")
        val_images, val_labels = self.load_dataset_laneD1(
            self.val_images_path,
            self.val_annotations_path
        )
        
        if len(train_images) == 0:
            raise ValueError("âŒ í›ˆë ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        
        # ğŸ†• ì „ì²´ ìš”ì•½ ì¶”ê°€
        total_data = len(train_images) + len(val_images)
        
        print(f"\n" + "=" * 60)
        print(f"âœ… ì „ì²´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        print("=" * 60)
        print(f"  ğŸ“Š í›ˆë ¨ ë°ì´í„°: {len(train_images):,}ê°œ")
        print(f"  ğŸ“Š ê²€ì¦ ë°ì´í„°: {len(val_images):,}ê°œ")
        print(f"  ğŸ“Š ì „ì²´ í•©ê³„: {total_data:,}ê°œ")
        print(f"  ğŸ“Š í›ˆë ¨/ê²€ì¦ ë¹„ìœ¨: {len(train_images)/total_data*100:.1f}% / {len(val_images)/total_data*100:.1f}%")
        
        # ë°ì´í„°ì…‹ ê· í˜• í™•ì¸
        if len(val_images) == 0:
            print(f"\n  âš ï¸ ê²½ê³ : ê²€ì¦ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
            print(f"     ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ê°€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤")
        elif len(val_images) / total_data < 0.1:
            print(f"\n  âš ï¸ ì£¼ì˜: ê²€ì¦ ë°ì´í„° ë¹„ìœ¨ì´ ë‚®ìŠµë‹ˆë‹¤ ({len(val_images)/total_data*100:.1f}%)")
            print(f"     ì¼ë°˜ì ìœ¼ë¡œ 10-20% ê¶Œì¥")
        elif len(val_images) / total_data > 0.3:
            print(f"\n  âš ï¸ ì£¼ì˜: ê²€ì¦ ë°ì´í„° ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤ ({len(val_images)/total_data*100:.1f}%)")
            print(f"     í›ˆë ¨ ë°ì´í„°ê°€ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        print("=" * 60)
        
        return train_images, train_labels, val_images, val_labels

# ============================================================================
# ğŸ“ 3ë‹¨ê³„: MobileNet ëª¨ë¸ êµ¬ì¶• (Model Builder)
# ============================================================================

class ModelBuilder:
    """
    MobileNet ê¸°ë°˜ CNN ëª¨ë¸ì„ ë§Œë“œëŠ” í´ë˜ìŠ¤
    
    [Transfer Learningì´ë€?]
    - ì´ë¯¸ ë‹¤ë¥¸ ì‘ì—…ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì„ ê°€ì ¸ì™€ì„œ ì‚¬ìš©
    - MobileNetì€ ImageNet(1,400ë§Œ ì¥)ìœ¼ë¡œ ì´ë¯¸ í•™ìŠµë¨
    - ì„ , ê³¡ì„ , ê²½ê³„ì„  ë“± ê¸°ë³¸ íŠ¹ì§•ì„ ì´ë¯¸ ì•Œê³  ìˆìŒ
    - ìš°ë¦¬ëŠ” "ì¡°í–¥ ì˜ˆì¸¡"ë§Œ ìƒˆë¡œ í•™ìŠµí•˜ë©´ ë¨!
    
    [ì™œ MobileNetì¸ê°€?]
    - âœ… ê²½ëŸ‰í™”ëœ ëª¨ë¸ (ëª¨ë°”ì¼ì—ì„œë„ ì‘ë™)
    - âœ… ë¹ ë¥¸ ì¶”ë¡  ì†ë„
    - âœ… ì ì€ íŒŒë¼ë¯¸í„°
    - âœ… ê²€ì¦ëœ ì„±ëŠ¥
    
    [ëª¨ë¸ êµ¬ì¡°]
    1. MobileNetV3Large (ê³ ì •): íŠ¹ì§• ì¶”ì¶œ
    2. GlobalAveragePooling2D: íŠ¹ì§• ì••ì¶•
    3. Dense ë ˆì´ì–´ë“¤: ì¡°í–¥ ê°ë„ ì˜ˆì¸¡
    """
    
    def __init__(self, config: TrainingConfig):
        self.config = config
    
    def build_mobilenet_model(self):
        """
        MobileNet ê¸°ë°˜ ëª¨ë¸ êµ¬ì¶•
        
        [êµ¬ì¡° ì„¤ëª…]
        
        ğŸ”’ ê³ ì • ë¶€ë¶„ (MobileNet):
        - ImageNetìœ¼ë¡œ ì‚¬ì „ í•™ìŠµë¨
        - ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§• ì¶”ì¶œ
        - í•™ìŠµí•˜ì§€ ì•ŠìŒ (trainable=False)
        
        ğŸ†• ìƒˆë¡œ í•™ìŠµí•  ë¶€ë¶„:
        - GlobalAveragePooling2D: íŠ¹ì§• ìš”ì•½
        - Dense(64): ì¤‘ê°„ ì˜ì‚¬ê²°ì •
        - Dense(32): ì„¸ë¶€ ì˜ì‚¬ê²°ì •
        - Dense(1): ìµœì¢… ì¡°í–¥ ê°ë„ ì¶œë ¥
        
        [ì¶œë ¥]
        - ìµœì¢… ì¡°í–¥ ì¶œë ¥: -1 ~ 1
        """
        print("\n" + "=" * 60)
        print("ğŸ—ï¸ MobileNet ê¸°ë°˜ ëª¨ë¸ êµ¬ì¶• ì¤‘...")
        print("=" * 60)
        
        print("\nğŸ’¡ Transfer Learning ì ìš©:")
        print("  - ì‚¬ì „í•™ìŠµ ë°ì´í„°: ImageNet (1,400ë§Œ ì¥)")
        print("  - ì‚¬ì „í•™ìŠµ ì¹´í…Œê³ ë¦¬: 1,000ê°œ (ë™ë¬¼, ì°¨ëŸ‰, ì‚¬ë¬¼ ë“±)")
        print("  - ê³ ì • ë¶€ë¶„: íŠ¹ì§• ì¶”ì¶œ ë ˆì´ì–´ (MobileNet)")
        print("  - í•™ìŠµ ë¶€ë¶„: ì¡°í–¥ ì˜ˆì¸¡ ë ˆì´ì–´ (Dense)")
        print("\nğŸ¯ ì¥ì :")
        print("  - ë¹ ë¥¸ í•™ìŠµ (50 ì—í¬í¬ë©´ ì¶©ë¶„)")
        print("  - ì ì€ ë°ì´í„°ë¡œ ë†’ì€ ì„±ëŠ¥")
        print("  - ì•ˆì •ì ì¸ í•™ìŠµ")
        
        # ===== 1. MobileNet ê¸°ë³¸ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° =====
        print("\nğŸ“¦ MobileNetV3Large ë¡œë“œ ì¤‘...")
        
        base_model = keras.applications.MobileNetV3Large(
            input_shape=(self.config.img_height, self.config.img_width, 3),
            include_top=False,   # ë¶„ë¥˜ì¸µ ì œì™¸ (ìš°ë¦¬ê°€ ì§ì ‘ ë§Œë“¤ ê²ƒ)
            weights='imagenet',  # ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©
            minimalistic=False,  # í‘œì¤€ êµ¬ì¡° ì‚¬ìš©
            alpha=0.75          # ëª¨ë¸ í¬ê¸° (0.75 = 25% ê²½ëŸ‰í™”)
        )
        
        # ===== 2. ê¸°ì¡´ í•™ìŠµ ë‚´ìš© ë³´ì¡´ =====
        # MobileNetì´ ë°°ìš´ ê²ƒì„ ê·¸ëŒ€ë¡œ ìœ ì§€
        base_model.trainable = False
        
        print(f"  âœ… MobileNet ë¡œë“œ ì™„ë£Œ")
        print(f"  ğŸ“Š ì´ ë ˆì´ì–´: {len(base_model.layers)}ê°œ")
        print(f"  ğŸ”’ ê³ ì • ìƒíƒœ: trainable=False")
        
        # ===== 3. ì¡°í–¥ ì˜ˆì¸¡ ë ˆì´ì–´ ì¶”ê°€ =====
        print("\nğŸ”§ ì¡°í–¥ ì˜ˆì¸¡ ë ˆì´ì–´ ì¶”ê°€ ì¤‘...")
        
        model = keras.Sequential([
            # ğŸ”’ ê³ ì •ëœ íŠ¹ì§• ì¶”ì¶œ (MobileNet)
            base_model,
            
            # íŠ¹ì§• ì••ì¶•
            layers.GlobalAveragePooling2D(),
            
            # ğŸ†• ìƒˆë¡œ í•™ìŠµí•  ì˜ì‚¬ê²°ì • ë ˆì´ì–´ë“¤
            layers.Dense(64, activation='relu', name='steering_fc1'),
            layers.Dropout(0.2, name='dropout1'),
            
            layers.Dense(32, activation='relu', name='steering_fc2'),
            
            # ìµœì¢… ì¡°í–¥ ì¶œë ¥: -1 ~ 1
            layers.Dense(1, activation='tanh', name='steering_output')
        ], name='BrainAI_Car_MobileNet')
        
        # ===== 4. ëª¨ë¸ ì»´íŒŒì¼ =====
        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=self.config.learning_rate),
            loss='mse',      # Mean Squared Error
            metrics=['mae']  # Mean Absolute Error
        )
        
        print("  âœ… ì¡°í–¥ ì˜ˆì¸¡ ë ˆì´ì–´ ì¶”ê°€ ì™„ë£Œ")
        
        # ===== 5. ëª¨ë¸ ì •ë³´ ì¶œë ¥ =====
        print("\n" + "=" * 60)
        print("âœ… ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ!")
        print("=" * 60)
        
        # íŒŒë¼ë¯¸í„° í†µê³„
        total_params = model.count_params()
        trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])
        non_trainable_params = total_params - trainable_params
        
        print(f"\nğŸ“Š ëª¨ë¸ í†µê³„:")
        print(f"  - ì „ì²´ íŒŒë¼ë¯¸í„°: {total_params:,}ê°œ")
        print(f"  - í•™ìŠµ íŒŒë¼ë¯¸í„°: {trainable_params:,}ê°œ (ì¡°í–¥ ì˜ˆì¸¡)")
        print(f"  - ê³ ì • íŒŒë¼ë¯¸í„°: {non_trainable_params:,}ê°œ (MobileNet)")
        print(f"  - í•™ìŠµ ë¹„ìœ¨: {trainable_params/total_params*100:.1f}%")
        
        print("\nğŸ“‹ ëª¨ë¸ êµ¬ì¡°:")
        model.summary()
        
        return model


# ============================================================================
# ğŸ“ 4ë‹¨ê³„: ëª¨ë¸ í›ˆë ¨ê¸° (Trainer)
# ============================================================================

class ModelTrainer:
    """
    ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ëŠ” í´ë˜ìŠ¤
    
    [í›ˆë ¨ ê³¼ì •]
    1. ë°ì´í„°ë¥¼ ëª¨ë¸ì— ë³´ì—¬ì£¼ê¸°
    2. ëª¨ë¸ì´ ì˜ˆì¸¡í•˜ê¸°
    3. ì˜ˆì¸¡ì´ ì–¼ë§ˆë‚˜ í‹€ë ¸ëŠ”ì§€ ê³„ì‚° (Loss)
    4. í‹€ë¦° ë§Œí¼ ëª¨ë¸ ì¡°ì •í•˜ê¸°
    5. 1~4ë¥¼ ë°˜ë³µ!
    
    [MobileNet í›ˆë ¨ íŠ¹ì§•]
    - ë¹ ë¥¸ ìˆ˜ë ´: 50 ì—í¬í¬ë©´ ì¶©ë¶„
    - ì•ˆì •ì : ì‚¬ì „ í•™ìŠµìœ¼ë¡œ ì´ˆê¸° ì„±ëŠ¥ ë†’ìŒ
    - ì¡°ê¸° ì¢…ë£Œ: ê°œì„  ì—†ìœ¼ë©´ ìë™ ì¤‘ë‹¨
    """
    
    def __init__(self, config: TrainingConfig, models_dir="models"):
        self.config = config
        self.model = None
        self.history = None
        
        # ëª¨ë¸ ì €ì¥ í´ë”
        self.models_dir = models_dir
        os.makedirs(self.models_dir, exist_ok=True)
    
    def setup_callbacks(self):
        """
        ì½œë°± ì„¤ì •
        
        [ì½œë°±ì´ë€?]
        - í›ˆë ¨ ì¤‘ ìë™ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ê¸°ëŠ¥ë“¤
        
        [MobileNet ìµœì í™” ì½œë°±]
        1. ModelCheckpoint: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        2. EarlyStopping: patience=5 (ì ë‹¹í•œ ì¸ë‚´)
        3. ReduceLROnPlateau: í•™ìŠµë¥  ìë™ ê°ì†Œ
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        model_path = os.path.join(
            self.models_dir,
            f"{self.config.model_name}_mobilenet_{timestamp}.keras"
        )
        
        callbacks = [
            # ğŸ“Œ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
            keras.callbacks.ModelCheckpoint(
                filepath=model_path,
                monitor='val_loss',
                save_best_only=True,
                verbose=1
            ),
            
            # ğŸ›‘ ì¡°ê¸° ì¢…ë£Œ (5 ì—í¬í¬ ë™ì•ˆ ê°œì„  ì—†ìœ¼ë©´)
            keras.callbacks.EarlyStopping(
                monitor='val_loss',
                patience=5,
                restore_best_weights=True,
                verbose=1
            ),
            
            # ğŸ“‰ í•™ìŠµë¥  ê°ì†Œ
            keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=5,
                min_lr=1e-7,
                verbose=1
            )
        ]
        
        print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {model_path}")
        
        return callbacks
    
    def train(self, model, train_images, train_labels, val_images, val_labels):
        """
        ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰
        
        [í™”ë©´ ì½ëŠ” ë²•]
        - Epoch: í˜„ì¬ ë°˜ë³µ íšŸìˆ˜
        - loss: í›ˆë ¨ ì˜¤ì°¨ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
        - mae: í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (ì˜ˆì¸¡ì´ í‰ê·  ëª‡ ë„ í‹€ë ¸ëŠ”ì§€)
        - val_loss: ê²€ì¦ ì˜¤ì°¨
        - val_mae: ê²€ì¦ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨
        
        [ì¢‹ì€ í•™ìŠµì˜ ì‹ í˜¸]
        âœ… lossì™€ val_lossê°€ ë¹„ìŠ·í•˜ê²Œ ê°ì†Œ
        âœ… maeê°€ 2ë„ ì´í•˜ë¡œ ìˆ˜ë ´
        âŒ val_lossê°€ ì¦ê°€ â†’ ê³¼ì í•©!
        """
        print("\n" + "=" * 60)
        print(f"ğŸš€ MobileNet ëª¨ë¸ í›ˆë ¨ ì‹œì‘ - {self.config.epochs} ì—í¬í¬")
        print("=" * 60)
        print("\nğŸ’¡ Tip:")
        print("  - MobileNetì€ ë¹ ë¥´ê²Œ ìˆ˜ë ´í•©ë‹ˆë‹¤")
        print("  - ë³´í†µ 20~50 ì—í¬í¬ë©´ ì¶©ë¶„í•©ë‹ˆë‹¤")
        print("  - val_lossê°€ ë” ì´ìƒ ê°ì†Œí•˜ì§€ ì•Šìœ¼ë©´ ìë™ ì¤‘ë‹¨ë©ë‹ˆë‹¤")
        print("=" * 60)
        
        callbacks = self.setup_callbacks()
        
        # í›ˆë ¨ ì‹œì‘!
        self.history = model.fit(
            train_images,
            train_labels,
            batch_size=self.config.batch_size,
            epochs=self.config.epochs,
            validation_data=(val_images, val_labels),
            callbacks=callbacks,
            verbose=1
        )
        
        self.model = model
        
        print("\nâœ… í›ˆë ¨ ì™„ë£Œ!")
        
        return self.history
    
    def evaluate(self, val_images, val_labels):
        """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
        print("\n" + "=" * 60)
        print("ğŸ“Š MobileNet ëª¨ë¸ í‰ê°€")
        print("=" * 60)
        
        loss, mae = self.model.evaluate(val_images, val_labels, verbose=0)
                
        print(f"\nê²€ì¦ ë°ì´í„° ì„±ëŠ¥:")
        print(f"  ğŸ“‰ Loss (MSE): {loss:.4f}")
        print(f"  ğŸ“ MAE: {mae:.4f}")
        
        # ì„±ëŠ¥ í‰ê°€ (ì¡°í–¥ê°’ ë²”ìœ„: -1~1, MAE 0.04 â‰ˆ ì‹¤ì œ 2ë„ ì˜¤ì°¨)
        if mae < 0.04:
            print(f"\n  ğŸ‰ ìš°ìˆ˜í•œ ì„±ëŠ¥ì…ë‹ˆë‹¤! (MAE < 0.04)")
        elif mae < 0.07:
            print(f"\n  âœ… ì¢‹ì€ ì„±ëŠ¥ì…ë‹ˆë‹¤! (MAE < 0.07)")
        elif mae < 0.10:
            print(f"\n  âš ï¸ ê°œì„  ì—¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤. (MAE < 0.10)")
        else:
            print(f"\n  âŒ ë°ì´í„°ë‚˜ ì„¤ì •ì„ ì ê²€í•´ë³´ì„¸ìš”.")
            
        # ì˜ˆì¸¡ ìƒ˜í”Œ
        print(f"\nğŸ¯ ì˜ˆì¸¡ ìƒ˜í”Œ (5ê°œ):")
        predictions = self.model.predict(val_images[:5], verbose=0)
        
        for i in range(5):
            actual = val_labels[i]
            predicted = predictions[i][0]
            error = abs(actual - predicted)
            
            print(f"  {i+1}. ì‹¤ì œ: {actual:6.3f} | "
                f"ì˜ˆì¸¡: {predicted:6.3f} | "
                f"ì˜¤ì°¨: {error:5.3f}")  
    
    def _setup_korean_font(self):
        """í•œê¸€ í°íŠ¸ ì„¤ì • (ì‹œìŠ¤í…œë³„ ëŒ€ì‘)"""
        system = platform.system()
        
        try:
            if system == 'Windows':
                plt.rcParams['font.family'] = 'Malgun Gothic'
            elif system == 'Darwin':  # macOS
                plt.rcParams['font.family'] = 'AppleGothic'
            else:  # Linux
                plt.rcParams['font.family'] = 'NanumGothic'
            
            # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€
            plt.rcParams['axes.unicode_minus'] = False
            
        except Exception as e:
            print("âš ï¸ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ë¬¸ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.")
    
    def plot_history(self):
        """í›ˆë ¨ ê³¼ì • ê·¸ë˜í”„ ê·¸ë¦¬ê¸°"""
        if self.history is None:
            print("âš ï¸ í›ˆë ¨ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        # í•œê¸€ í°íŠ¸ ì„¤ì •
        self._setup_korean_font()
        
        plt.figure(figsize=(12, 4))
           
        # Loss ê·¸ë˜í”„
        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['loss'], label='í›ˆë ¨ Loss', linewidth=2)
        plt.plot(self.history.history['val_loss'], label='ê²€ì¦ Loss', linewidth=2)
        plt.title('MobileNet ëª¨ë¸ Loss', fontsize=14, fontweight='bold')
        plt.xlabel('ì—í¬í¬', fontsize=12)
        plt.ylabel('Loss', fontsize=12)
        plt.legend(fontsize=10)
        plt.grid(True, alpha=0.3)
        
        # MAE ê·¸ë˜í”„
        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['mae'], label='í›ˆë ¨ MAE', linewidth=2)
        plt.plot(self.history.history['val_mae'], label='ê²€ì¦ MAE', linewidth=2)
        plt.title('í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE)', fontsize=14, fontweight='bold')
        plt.xlabel('ì—í¬í¬', fontsize=12)
        plt.ylabel('MAE', fontsize=12)
        plt.legend(fontsize=10)
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ì €ì¥
        plot_path = os.path.join(
            self.models_dir,
            f"{self.config.model_name}_mobilenet_history.png"
        )
        plt.savefig(plot_path, dpi=150)
        print(f"\nğŸ“Š í›ˆë ¨ ê·¸ë˜í”„ ì €ì¥: {plot_path}")
        
        plt.show()
    
    def save_final_model(self):
        """ìµœì¢… ëª¨ë¸ ì €ì¥"""
        if self.model is None:
            print("âš ï¸ ì €ì¥í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        save_path = os.path.join(
            self.models_dir,
            f"{self.config.model_name}_mobilenet_final.keras"
        )
        self.model.save(save_path)
        print(f"\nğŸ’¾ ìµœì¢… ëª¨ë¸ ì €ì¥: {save_path}")


# ============================================================================
# ğŸ“ 5ë‹¨ê³„: í†µí•© í›ˆë ¨ í•¨ìˆ˜
# ============================================================================

def model_train(config: TrainingConfig, models_dir="models"):
    """
    ì „ì²´ í›ˆë ¨ ê³¼ì • ì‹¤í–‰ í•¨ìˆ˜
    
    [MobileNet Transfer Learning ì „ì²´ íë¦„]
    1. ì„¤ì • ì¶œë ¥
    2. ë°ì´í„° ë¡œë“œ (MobileNet ì „ì²˜ë¦¬)
    3. MobileNet ëª¨ë¸ êµ¬ì¶•
    4. ëª¨ë¸ í›ˆë ¨
    5. ì„±ëŠ¥ í‰ê°€
    6. ê²°ê³¼ ì €ì¥
    
    [ì™œ MobileNetì¸ê°€?]
    - âš¡ ë¹ ë¥¸ í•™ìŠµ: Custom CNN ëŒ€ë¹„ 50% ì‹œê°„ ì ˆì•½
    - ğŸ¯ ë†’ì€ ì„±ëŠ¥: ì ì€ ë°ì´í„°ë¡œë„ ìš°ìˆ˜í•œ ê²°ê³¼
    - ğŸ’ª ì•ˆì •ì : ì‚¬ì „ í•™ìŠµìœ¼ë¡œ ì•ˆì •ì ì¸ ìˆ˜ë ´
    - ğŸŒ ì‹¤ë¬´ í‘œì¤€: ì—…ê³„ì—ì„œ ë„ë¦¬ ì‚¬ìš©
    
    Args:
        config: í›ˆë ¨ ì„¤ì •
        models_dir: ëª¨ë¸ ì €ì¥ í´ë”
    """
    # GPU ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print(f"âœ… GPU {len(gpus)}ê°œ ë°œê²¬ - ë©”ëª¨ë¦¬ ì¦ê°€ ì œí•œ í™œì„±í™”")
        except RuntimeError as e:
            print(f"âš ï¸ GPU ì„¤ì • ì‹¤íŒ¨: {e}")
    else:
        print("â„¹ï¸ GPU ì—†ìŒ - CPUë¡œ í›ˆë ¨ (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    
    # Transfer Learning ì•ˆë‚´
    print("\n" + "=" * 60)
    print("ğŸ“ Transfer Learning with MobileNet")
    print("=" * 60)
    print("\n[Transfer Learningì´ë€?]")
    print("  ì´ë¯¸ ë‹¤ë¥¸ ì‘ì—…ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì„ í™œìš©í•˜ëŠ” ê¸°ë²•")
    print("\n[MobileNet ì‚¬ì „ í•™ìŠµ ì •ë³´]")
    print("  - ë°ì´í„°: ImageNet (1,400ë§Œ ì¥)")
    print("  - ì¹´í…Œê³ ë¦¬: 1,000ê°œ (ë™ë¬¼, ì°¨ëŸ‰, ì‚¬ë¬¼ ë“±)")
    print("  - í•™ìŠµ ë‚´ìš©: ì„ , ê³¡ì„ , ê²½ê³„, ì§ˆê°, íŒ¨í„´ ë“±")
    print("\n[ìš°ë¦¬ê°€ í•  ì¼]")
    print("  - MobileNet: íŠ¹ì§• ì¶”ì¶œ (ì´ë¯¸ í•™ìŠµë¨, ê³ ì •)")
    print("  - Dense ë ˆì´ì–´: ì¡°í–¥ ì˜ˆì¸¡ (ìƒˆë¡œ í•™ìŠµ)")
    print("\n[ì¥ì ]")
    print("  âš¡ ë¹ ë¥¸ í•™ìŠµ ì†ë„ (50 ì—í¬í¬ë©´ ì¶©ë¶„)")
    print("  ğŸ¯ ë†’ì€ ì´ˆê¸° ì„±ëŠ¥ (ì²« ì—í¬í¬ë¶€í„° ì¢‹ì€ ê²°ê³¼)")
    print("  ğŸ’¾ ì ì€ ë°ì´í„° í•„ìš” (500~1,000ì¥ìœ¼ë¡œë„ ê°€ëŠ¥)")
    
    config.print_summary()
    
    try:
        # 1ï¸âƒ£ ë°ì´í„° ë¡œë” ìƒì„± ë° ë°ì´í„° ë¡œë“œ
        data_loader = DataLoader(config)
        train_images, train_labels, val_images, val_labels = data_loader.load_all_data()
        
        # 2ï¸âƒ£ MobileNet ëª¨ë¸ êµ¬ì¶•
        model_builder = ModelBuilder(config)
        model = model_builder.build_mobilenet_model()
        
        # 3ï¸âƒ£ íŠ¸ë ˆì´ë„ˆë¡œ ëª¨ë¸ í›ˆë ¨
        trainer = ModelTrainer(config, models_dir)
        trainer.train(model, train_images, train_labels, val_images, val_labels)
        
        # 4ï¸âƒ£ ì„±ëŠ¥ í‰ê°€
        trainer.evaluate(val_images, val_labels)
        
        # 5ï¸âƒ£ ìµœì¢… ëª¨ë¸ ì €ì¥
        trainer.save_final_model()
        
        # 6ï¸âƒ£ í›ˆë ¨ ê·¸ë˜í”„ ìƒì„±
        trainer.plot_history()
        
        # ì™„ë£Œ ë©”ì‹œì§€
        print("\n" + "=" * 60)
        print("âœ… MobileNet í›ˆë ¨ ì™„ë£Œ!")
        print("=" * 60)
        print("\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
        print("  â€¢ models/ í´ë”ì— í›ˆë ¨ëœ MobileNet ëª¨ë¸")
        print("  â€¢ í›ˆë ¨ ê·¸ë˜í”„ ì´ë¯¸ì§€")
        print("\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
        print("  1. ììœ¨ì£¼í–‰ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        print("  2. ì„±ëŠ¥ì´ ë¶€ì¡±í•˜ë©´ Fine-tuning ì‹¤í–‰")
        print("  3. ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘ í›„ ëª¨ë¸ ì—…ë°ì´íŠ¸")
        print("\nğŸ’¡ Fine-tuningì´ë€?")
        print("  - MobileNetì˜ ì¼ë¶€ ë ˆì´ì–´ ì¼ë¶€ë¥¼ í•™ìŠµ ê°€ëŠ¥ ìƒíƒœë¡œ ì „í™˜í•˜ì—¬ ì¶”ê°€ë¡œ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ê³¼ì •")
        print("  - ë„ë¡œ ì¸ì‹ì— ë” íŠ¹í™”ë˜ê²Œ ìµœì í™”")
        print("  - update_model.py ì‚¬ìš©")
        
    except ValueError as e:
        print(f"\nâŒ ë°ì´í„° ì˜¤ë¥˜: {e}")
        print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
        print("  1. dataset_laneD1 í´ë” êµ¬ì¡° í™•ì¸:")
        print("     dataset_laneD1/")
        print("     â”œâ”€â”€ train/")
        print("     â”‚   â”œâ”€â”€ images/")
        print("     â”‚   â””â”€â”€ annotations/")
        print("     â””â”€â”€ validation/")
        print("         â”œâ”€â”€ images/")
        print("         â””â”€â”€ annotations/")
        print("  2. ì´ë¯¸ì§€ì™€ JSON íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸")
        print("  3. MobileNetì€ ì ì€ ë°ì´í„°ë¡œë„ ì‘ë™í•˜ì§€ë§Œ")
        print("     ìµœì†Œ 500ì¥ ì´ìƒ ê¶Œì¥")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        print("\nğŸ’¡ ë¬¸ì œ í•´ê²°:")
        print("  1. ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì˜ ì½ì–´ë³´ì„¸ìš”")
        print("  2. ì„ ìƒë‹˜ê»˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”")
        print("  3. TensorFlowê°€ ì œëŒ€ë¡œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸")


# ë²„ì „ ì •ë³´
__version__ = '1.0.0'
__author__ = 'BrainAI Co,.Ltd.'
__description__ = 'BrainAI Autonomous Driving Project - MobileNet Transfer Learning Module'